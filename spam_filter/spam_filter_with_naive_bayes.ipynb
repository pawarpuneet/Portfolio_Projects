{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50967ebb",
   "metadata": {},
   "source": [
    "# Spam filter\n",
    "Spam is most commonly associated with emails. For instance, unwanted and unsolicited advertising emails are usually classified as spam. Spamming, however, occurs in ways and environments that don't necessarily relate to emails:\n",
    "\n",
    "- Articles or blog posts can be spammed with comments — the comments are ads or they are repetitive.\n",
    "- An educational forum may be spammed with posts that are, in fact, ads.\n",
    "- Mobile phone users may receive unwanted and unsolicited SMS messages, usually about advertising. \n",
    "\n",
    "We are going to build a spam filter specifically directed at preventing mobile phone spam. The filter will be able to analyze new messages and tell whether they are spam or not — this way, we might be able to prevent spam from bothering mobile phone users. Our goal is to create a spam filter that classifies new messages with an accuracy greater than 80% — so we expect that more than 80% of the new messages will be classified correctly as spam or ham (non-spam).\n",
    "\n",
    "We'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans.\n",
    "\n",
    "The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the The [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).\n",
    "\n",
    "Note that due to the nature of spam messages, the dataset contains content that may be offensive to some users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb004a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd84e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('SMSSpamCollection',header=None, names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770ad865",
   "metadata": {},
   "source": [
    "### Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d003c7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8584808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b937be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Label   5572 non-null   object\n",
      " 1   SMS     5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32eee29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d6289b",
   "metadata": {},
   "source": [
    "In out dataset we have 86.5% non-spam (ham) messages and 13.5% spam messages.\n",
    "\n",
    "### Training and Test Set\n",
    "We're going to keep 80% of our dataset for training, and 20% for testing, which means that:\n",
    "\n",
    "- The training set will have 4,458 messages (about 80% of the dataset).\n",
    "- The test set will have 1,114 messages (about 20% of the dataset).\n",
    "\n",
    "We will randomize the entire dataset to ensure that spam and ham messages are spread properly throughout the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc1736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test set, to ensure the class distribution is maintained use stratify parameter\n",
    "\n",
    "data_train, data_test = train_test_split(\n",
    "    data,\n",
    "    test_size=0.2,\n",
    "    random_state=1,\n",
    "    stratify=data['Label']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a3a7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.865829\n",
       "spam    0.134171\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = data_train.reset_index(drop=True)\n",
    "data_train['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5e2db27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.866368\n",
       "spam    0.133632\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = data_test.reset_index(drop=True)\n",
    "data_test['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677742de",
   "metadata": {},
   "source": [
    "The percentage of spam and ham in both the training and the test set are similar to what we have in the full dataset.\n",
    "\n",
    "### Data Cleaning: Letter Case and Punctuation\n",
    "Let's begin the data cleaning process by removing the punctuation and bringing all the words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "babc1c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>no  he joined today itself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>will ü b going to esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>reply to win  100 weekly  what professional sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>awesome  lemme know whenever you re around</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>private  your 2003 account statement for shows...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                        no  he joined today itself \n",
       "1   ham               will ü b going to esplanade fr home \n",
       "2  spam  reply to win  100 weekly  what professional sp...\n",
       "3   ham         awesome  lemme know whenever you re around\n",
       "4  spam  private  your 2003 account statement for shows..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all punctuation from SMS column\n",
    "data_train['SMS'] = data_train['SMS'].str.replace(r'\\W', ' ', regex=True).str.lower()\n",
    "data_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9889e4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok i shall talk to him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eatin my lunch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sir, Waiting for your mail.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wif my family booking tour package.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. It's not pride. I'm almost  &amp;lt;#&amp;gt;  yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                             Ok i shall talk to him\n",
       "1   ham                                  Eatin my lunch...\n",
       "2   ham                        Sir, Waiting for your mail.\n",
       "3   ham                Wif my family booking tour package.\n",
       "4   ham  No. It's not pride. I'm almost  &lt;#&gt;  yea..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc977ab3",
   "metadata": {},
   "source": [
    "###  Creating the Vocabulary\n",
    "Let's create a list with all of the unique words that occur in the messages of our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b833af17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'he', 'joined', 'today', 'itself', 'will', 'ü', 'b', 'going', 'to']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Counter()\n",
    "data_train['sms_words'] = data_train['SMS'].str.strip().str.split('\\s+')\n",
    "data_train['sms_words'] .apply(words.update)\n",
    "vocab = list(words.keys())\n",
    "vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed899c2",
   "metadata": {},
   "source": [
    "### The Final Training Set\n",
    "We need a transformed table that represents a unique word in our vocabulary where each column shows the frequency of that unique word for any given message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e069841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {word:[0]*len(data_train) for word in vocab}\n",
    "\n",
    "for i,sms in enumerate(data_train['sms_words']):\n",
    "    for word in sms:\n",
    "        vocab_dict[word][i] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3233cc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>he</th>\n",
       "      <th>joined</th>\n",
       "      <th>today</th>\n",
       "      <th>itself</th>\n",
       "      <th>will</th>\n",
       "      <th>ü</th>\n",
       "      <th>b</th>\n",
       "      <th>going</th>\n",
       "      <th>to</th>\n",
       "      <th>...</th>\n",
       "      <th>yowifes</th>\n",
       "      <th>hint</th>\n",
       "      <th>helens</th>\n",
       "      <th>princes</th>\n",
       "      <th>arguing</th>\n",
       "      <th>gailxx</th>\n",
       "      <th>betta</th>\n",
       "      <th>aging</th>\n",
       "      <th>products</th>\n",
       "      <th>badrith</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   no  he  joined  today  itself  will  ü  b  going  to  ...  yowifes  hint  \\\n",
       "0   1   1       1      1       1     0  0  0      0   0  ...        0     0   \n",
       "1   0   0       0      0       0     1  1  1      1   1  ...        0     0   \n",
       "2   0   0       0      0       0     0  0  0      0   3  ...        0     0   \n",
       "3   0   0       0      0       0     0  0  0      0   0  ...        0     0   \n",
       "4   0   0       0      0       0     0  0  0      0   0  ...        0     0   \n",
       "\n",
       "   helens  princes  arguing  gailxx  betta  aging  products  badrith  \n",
       "0       0        0        0       0      0      0         0        0  \n",
       "1       0        0        0       0      0      0         0        0  \n",
       "2       0        0        0       0      0      0         0        0  \n",
       "3       0        0        0       0      0      0         0        0  \n",
       "4       0        0        0       0      0      0         0        0  \n",
       "\n",
       "[5 rows x 7671 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(vocab_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63b640a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 7671)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b24f802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>sms_words</th>\n",
       "      <th>no</th>\n",
       "      <th>he</th>\n",
       "      <th>joined</th>\n",
       "      <th>today</th>\n",
       "      <th>itself</th>\n",
       "      <th>will</th>\n",
       "      <th>ü</th>\n",
       "      <th>...</th>\n",
       "      <th>yowifes</th>\n",
       "      <th>hint</th>\n",
       "      <th>helens</th>\n",
       "      <th>princes</th>\n",
       "      <th>arguing</th>\n",
       "      <th>gailxx</th>\n",
       "      <th>betta</th>\n",
       "      <th>aging</th>\n",
       "      <th>products</th>\n",
       "      <th>badrith</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>no  he joined today itself</td>\n",
       "      <td>[no, he, joined, today, itself]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>will ü b going to esplanade fr home</td>\n",
       "      <td>[will, ü, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>reply to win  100 weekly  what professional sp...</td>\n",
       "      <td>[reply, to, win, 100, weekly, what, profession...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>awesome  lemme know whenever you re around</td>\n",
       "      <td>[awesome, lemme, know, whenever, you, re, around]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>private  your 2003 account statement for shows...</td>\n",
       "      <td>[private, your, 2003, account, statement, for,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7674 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  \\\n",
       "0   ham                        no  he joined today itself    \n",
       "1   ham               will ü b going to esplanade fr home    \n",
       "2  spam  reply to win  100 weekly  what professional sp...   \n",
       "3   ham         awesome  lemme know whenever you re around   \n",
       "4  spam  private  your 2003 account statement for shows...   \n",
       "\n",
       "                                           sms_words  no  he  joined  today  \\\n",
       "0                    [no, he, joined, today, itself]   1   1       1      1   \n",
       "1       [will, ü, b, going, to, esplanade, fr, home]   0   0       0      0   \n",
       "2  [reply, to, win, 100, weekly, what, profession...   0   0       0      0   \n",
       "3  [awesome, lemme, know, whenever, you, re, around]   0   0       0      0   \n",
       "4  [private, your, 2003, account, statement, for,...   0   0       0      0   \n",
       "\n",
       "   itself  will  ü  ...  yowifes  hint  helens  princes  arguing  gailxx  \\\n",
       "0       1     0  0  ...        0     0       0        0        0       0   \n",
       "1       0     1  1  ...        0     0       0        0        0       0   \n",
       "2       0     0  0  ...        0     0       0        0        0       0   \n",
       "3       0     0  0  ...        0     0       0        0        0       0   \n",
       "4       0     0  0  ...        0     0       0        0        0       0   \n",
       "\n",
       "   betta  aging  products  badrith  \n",
       "0      0      0         0        0  \n",
       "1      0      0         0        0  \n",
       "2      0      0         0        0  \n",
       "3      0      0         0        0  \n",
       "4      0      0         0        0  \n",
       "\n",
       "[5 rows x 7674 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([data_train, df], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66bc6de",
   "metadata": {},
   "source": [
    "### Calculating Constants\n",
    "\n",
    "Now that we're done with data cleaning and have a training set to work with, we can begin creating the spam filter. \n",
    "\n",
    "Naive Bayes algorithm will make the classification based on the results it gets to these two equations:\n",
    "$$P(Spam|w1,w2,...,wn)∝P(Spam)⋅ \\prod_{i=1}^n P(wi|Spam)$$\n",
    "$$P(Ham|w1,w2,...,wn)∝P(Ham)⋅ \\prod_{i=1}^n P(wi|Ham)$$\n",
    "\n",
    "To calculate P(wi|Spam) and P(wi|Ham) inside the formulas above, we need to use these equations:\n",
    "$$P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}$$\n",
    "$$P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}$$\n",
    "\n",
    "Where:   \n",
    "$N_{w_i|Spam}$=the number of times the word wi occurs in spam messages   \n",
    "$N_{w_i|Ham}$=the number of times the word wi occurs in non-spam messages   \n",
    "$N_{Spam}$=total number of words in spam messages   \n",
    "$N_{Ham}$=total number of words in non-spam messages   \n",
    "$N_{Vocabulary}$=total number of words in the vocabulary   \n",
    "$α=1$    (α is a smoothing parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "864ea0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_ham = 0.8658290329818263, p_spam = 0.13417096701817366, n_spam = 15290, n_ham = 56729, n_vocab = 7671, alpha = 1\n"
     ]
    }
   ],
   "source": [
    "# total number of words in spam messages\n",
    "n_spam = final_df.loc[final_df.Label == 'spam','sms_words'].apply(len).sum()\n",
    "# total number of words in ham messages\n",
    "n_ham = final_df.loc[final_df.Label == 'ham','sms_words'].apply(len).sum()\n",
    "# total number of words in vocabulary\n",
    "n_vocab = len(vocab)\n",
    "# smoothing parameter set to 1 for Laplace smoothing\n",
    "alpha = 1\n",
    "\n",
    "proprotion = final_df['Label'].value_counts(normalize=True)\n",
    "p_spam = proprotion['spam']\n",
    "p_ham = proprotion['ham']\n",
    "\n",
    "print(f'p_ham = {p_ham}, p_spam = {p_spam}, n_spam = {n_spam}, n_ham = {n_ham}, n_vocab = {n_vocab}, alpha = {alpha}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b01b8b",
   "metadata": {},
   "source": [
    "### Calculating Parameters\n",
    "\n",
    "Now let's calculate the parameters using these equations:\n",
    "$$P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}$$\n",
    "$$P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}$$\n",
    "\n",
    "We will create two dictionaries - one for spam and ham each. The keys will be the words and values will be $P(w_i|Spam)$ and $P(w_i|Ham)$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9b9228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dictionaries with 0 value for each word in vocab\n",
    "p_wi_spam = {word:0 for word in vocab}\n",
    "p_wi_ham = {word:0 for word in vocab}\n",
    "\n",
    "\n",
    "spam_only = final_df[final_df.Label == 'spam']\n",
    "ham_only = final_df[final_df.Label == 'ham']\n",
    "\n",
    "n_wi_spam = spam_only.iloc[:, 3:].sum()\n",
    "n_wi_ham = ham_only.iloc[:, 3:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0af23b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no         52\n",
       "he          0\n",
       "joined      2\n",
       "today      18\n",
       "itself      0\n",
       "will       37\n",
       "ü           0\n",
       "b           9\n",
       "going       3\n",
       "to        546\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_wi_spam.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be69957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no 0.0023082618352859197\n",
      "he 4.3552110099734335e-05\n",
      "joined 0.000130656330299203\n",
      "today 0.0008274900918949523\n",
      "itself 4.3552110099734335e-05\n",
      "will 0.0016549801837899046\n",
      "ü 4.3552110099734335e-05\n",
      "b 0.0004355211009973433\n",
      "going 0.00017420844039893734\n",
      "to 0.02382300422455468\n"
     ]
    }
   ],
   "source": [
    "# calculate p_wi_spam\n",
    "for word,v in p_wi_spam.items():\n",
    "    p_wi_spam[word] = (n_wi_spam[word] + alpha)/(n_spam + (alpha*n_vocab))\n",
    "    \n",
    "for k,v in islice(p_wi_spam.items(),10):\n",
    "    print(k,v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "caa987b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no 0.0036645962732919255\n",
      "he 0.0026086956521739132\n",
      "joined 9.316770186335404e-05\n",
      "today 0.0018167701863354038\n",
      "itself 0.00015527950310559007\n",
      "will 0.004239130434782609\n",
      "ü 0.00218944099378882\n",
      "b 0.0009472049689440994\n",
      "going 0.0020496894409937887\n",
      "to 0.019580745341614907\n"
     ]
    }
   ],
   "source": [
    "# calculate p_wi_ham\n",
    "for word,v in p_wi_spam.items():\n",
    "    p_wi_ham[word] = (n_wi_ham[word] + alpha)/(n_ham + (alpha*n_vocab))\n",
    "\n",
    "for k,v in islice(p_wi_ham.items(),10):\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b89e72",
   "metadata": {},
   "source": [
    "### Classifying a new message\n",
    "Now that we've calculated all the constants and parameters we need, we can start creating the spam filter. The spam filter will be a function that:\n",
    "\n",
    "- Takes in as input a new message (w1, w2, ..., wn). \n",
    "- Calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)\n",
    "- Compares the values of P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn), and:\n",
    "    - If P(Ham|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), then the message is classified as ham.\n",
    "    - If P(Ham|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), then the message is classified as spam.\n",
    "    - If P(Ham|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), then the algorithm may request human help.\n",
    "\n",
    "Where:\n",
    "$$P(Spam|w1,w2,...,wn)∝P(Spam)⋅ \\prod_{i=1}^n P(wi|Spam)$$\n",
    "$$P(Ham|w1,w2,...,wn)∝P(Ham)⋅ \\prod_{i=1}^n P(wi|Ham)$$\n",
    "\n",
    "Note that some new messages will contain words that are not part of the vocabulary. We will ignore these words when we're calculating the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44da43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input variable message is assumed to be a string\n",
    "\n",
    "def classify(sms):\n",
    "    sms = re.sub('\\W', ' ', sms) # replace all punctuation with a single space\n",
    "    sms = re.sub('\\s+', ' ', sms) # replace multiple spaces with a single space\n",
    "    sms = sms.strip().split(' ') #split words into a list\n",
    "\n",
    "    p_spam_given_sms = p_spam\n",
    "    p_ham_given_sms = p_ham\n",
    "    for word in sms:\n",
    "        if word in vocab:\n",
    "            p_spam_given_sms *= p_wi_spam[word]\n",
    "            p_ham_given_sms *= p_wi_ham[word]\n",
    "    #print(p_spam_given_sms, p_ham_given_sms)\n",
    "    if p_spam_given_sms > p_ham_given_sms:\n",
    "        return 'spam'\n",
    "    elif p_ham_given_sms > p_spam_given_sms:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'needs human classification'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be5e6700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "classify(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5642a321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = 'Sounds good, Tom, then see u there'\n",
    "classify(test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de70403",
   "metadata": {},
   "source": [
    "### Measuring the Spam Filter's Accuracy\n",
    "We managed to create a spam filter, and we classified two new messages. We'll now try to determine how well the spam filter does on our test set of 1,115 messages.\n",
    "\n",
    "Now we can compare the predicted values with the actual values to measure how good our spam filter is with classifying new messages. To make the measurement, we'll use accuracy as a metric:\n",
    "\n",
    "$$\\text{Acurracy} = \\frac{{\\text{number of correctly classified messages}}} {\\text{total number of classified messages}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "215300eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok i shall talk to him</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eatin my lunch...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sir, Waiting for your mail.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wif my family booking tour package.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. It's not pride. I'm almost  &amp;lt;#&amp;gt;  yea...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham                             Ok i shall talk to him       ham\n",
       "1   ham                                  Eatin my lunch...       ham\n",
       "2   ham                        Sir, Waiting for your mail.       ham\n",
       "3   ham                Wif my family booking tour package.       ham\n",
       "4   ham  No. It's not pride. I'm almost  &lt;#&gt;  yea...       ham"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['predicted'] = data_test['SMS'].apply(classify)\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12f311e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted\n",
       "ham     975\n",
       "spam    140\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['predicted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c717fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_test['Label'] != data_test['predicted']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7a27477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.29596412556054"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_correct = (data_test['Label'] == data_test['predicted']).sum()\n",
    "n_total = data_test.shape[0]\n",
    "accuracy = n_correct*100/n_total\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbfe8ae",
   "metadata": {},
   "source": [
    "Filter has an accuracy of 98.29%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f2462",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we managed to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. The filter has an accuracy of 98.29% on the test set, which is an excellent result. We initially aimed for an accuracy of over 80%, but we managed to do way better than that.\n",
    "\n",
    "Next Steps:\n",
    "Filter classified 19 sms incorrectly and we can improve the accuracy further by making the algorithm sensitive to letter case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4cb301",
   "metadata": {},
   "source": [
    "### Author\n",
    "Puneet Pawar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
